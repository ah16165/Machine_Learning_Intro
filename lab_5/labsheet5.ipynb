{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Introduction to Classification\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this lab we will play a little with data classification. We will deal with the famous [Iris flower dataset](http://archive.ics.uci.edu/ml/datasets/Iris). \n",
    "\n",
    "We will first visualise its features and will then train a simple classifier to predict the class of unknown samples. \n",
    "\n",
    "We finally will __qualitatively__ analyse the results. This means that we will only observe the results in a graphical way and try to make sense of the classifier's behaviour. In the next lab, instead, we will analyse the results in a __quantitative__ way, i.e. by using some metric that quantifies the performance of the classifier.\n",
    "\n",
    "__Note__: you will need to reuse much of the code you'll write here for the next lab sessions, __as well as for Coursework 2__. You should thus try to write your code as neat and reusable as you can (i. e. use functions!).\n",
    "\n",
    "As usual, let's import the libraries before we start by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function # to avoid issues between Python 2 and 3 printing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from voronoi import plot_voronoi\n",
    "\n",
    "# show matplotlib figures inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# By default we set figures to be 12\"x8\" on a 110 dots per inch (DPI) screen \n",
    "# (adjust DPI if you have a high res screen!)\n",
    "plt.rc('figure', figsize=(12, 8), dpi=110)\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris flower dataset\n",
    "\n",
    "The Iris Flower Dataset is a classic in machine learning. It contains 150 samples, each describing four different characteristics of the [Iris Flower](https://en.wikipedia.org/wiki/Iris_(plant)):\n",
    "\n",
    "1. sepal length\n",
    "2. sepal width\n",
    "3. petal length\n",
    "4. petal width\n",
    "\n",
    "All features are expressed in centimetres. The dataset contains samples from three different species of Iris flowers: \n",
    "\n",
    "1. Iris Setosa\n",
    "2. Iris Versicolour\n",
    "3. Iris Virginica\n",
    "\n",
    "There are 50 samples for each species. We split the dataset in two sets: a __training__ set, containing 100 samples, which will be used for training a classifier, and a __test__ set, containing 50 samples, which will be used to evaluate the classifier.\n",
    "\n",
    "Run the cell below to load the dataset in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load the iris train and test sets\n",
    "\n",
    "def load_iris_data(train_path='iris_train.csv', test_path='iris_test.csv'):\n",
    "    train_set = np.loadtxt(train_path, delimiter=',')\n",
    "    test_set = np.loadtxt(test_path, delimiter=',')\n",
    "\n",
    "    # separate labels from features\n",
    "    train_labels = train_set[:, 4].astype(np.int)\n",
    "    train_set = train_set[:, 0:4]\n",
    "    test_labels = test_set[:, 4].astype(np.int)\n",
    "    test_set = test_set[:, 0:4]\n",
    "    \n",
    "    return train_labels, train_set, test_labels, test_set\n",
    "\n",
    "train_labels, train_set, test_labels, test_set = load_iris_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_set` and `test_set` are NumPy arrays of shape `(100, 4)` and `(50, 4)` respectively. Rows correspond to individual samples, while columns correspond to the aforementioned flowers' characteristics.\n",
    "`train_labels` and `test_labels` are NumPy arrays of shape `(100,)` and `(50,)` and contain the class/species label of each sample, i.e. either 1, 2 or 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualising the data\n",
    "\n",
    "Let's now visualise the data in the __training set__. We want to plot all the pairwise feature combinations, e.g. `train_set[:, 0]` vs `train_set[:, 1]`, `train_set[:, 0]` vs `train_set[:, 2]` and so on. The aim is to see how different pairs of features separate the data into the three classes.\n",
    "\n",
    "You should obtain a plot like the one below. The three colours correspond to the three different species/classes: \n",
    "\n",
    "1. Iris Setosa: <font color='#3366ff'> blue</font>\n",
    "2. Iris Versicolour: <font color='#cc3300'> red</font>\n",
    "3. Iris Virginica: <font color='#ffc34d'> yellow</font>\n",
    "\n",
    "Let's state some obvious facts too: \n",
    "1. The plot matrix is symmetrical, as in features (x, y) separate the data the same way as (y, x). Notice that due to the axis scaling not being symmetrical, however, the scatter plots might not look symmetrical; \n",
    "2. Plots along the main diagonal show one feature only.\n",
    "\n",
    "![](iris_scatter_plots.png)\n",
    "\n",
    "__Hints__: \n",
    "\n",
    "- Use the `train_labels` to assign each data point a different colour according to its class. \n",
    "- The function `plt.scatter` takes an optional parameter `c` that can be used to change the colour of the points. \n",
    "\n",
    "We are providing you with some code to setup the subplots so that they don't look crammed, as well as the colour codes we used for the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train_set.shape[1]\n",
    "fig, ax = plt.subplots(n_features, n_features)\n",
    "plt.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01, wspace=0.2, hspace=0.4)\n",
    "\n",
    "class_1_colour = r'#3366ff'\n",
    "class_2_colour = r'#cc3300'\n",
    "class_3_colour = r'#ffc34d'\n",
    "\n",
    "class_colours = [class_1_colour, class_2_colour, class_3_colour]\n",
    "\n",
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "Observe now the scatter plots. As you will notice, certain pairs of features separate the data better than others. This is because the characteristics of the flowers exhibit different degrees of correlation.\n",
    "\n",
    "Select __two__ features only that, according to you, best separate the data into the respective classes. Note that one class is linearly separable from the others, while the remaining two are not linearly separable from each other. \n",
    "\n",
    "Discuss your decision with a TA. Once you have picked up your pair of features, reduce __both__ the training and testing set so that you use only your selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nearest-Centroid classifier\n",
    "\n",
    "Implement the Nearest-Centroid classifier. You will need to follow the steps listed below.\n",
    "\n",
    "### 3.1. Calculate the centroid for each class, using the reduced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Display a scatter plot of the reduced training set, along with the calculated centroids \n",
    "\n",
    "You should produce a plot similat to the one below (legend included).\n",
    "\n",
    "![](iris_train.png)\n",
    "\n",
    "__Hints__:\n",
    "- Use marker `'o'` with size `300` for the centroids\n",
    "- Use the list of colours `class_colours` we provided above to distinguish the three classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Classify each sample in the reduced test set using your classifier. \n",
    "\n",
    "Do __NOT__ use the provided test labels to classify the samples. Print the predicted class and the ground truth class for each test sample.\n",
    "\n",
    "Write your results to a CSV file. __You will need__ this text file for the next lab session, so make sure you save your results! You can use [`np.savetxt(path, results, delimiter=',', fmt='%d')`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html) for this purpose. You should save only the predicted class for each sample in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Display a scatter plot of the reduced test set.\n",
    "\n",
    "Use the provided test labels to change the colour of each point according to its ground truth class. Overlay a __Voronoi__ plot to display the decision boundaries of your classifier. \n",
    "\n",
    "You should produce a plot similar to the one below.\n",
    "\n",
    "![](iris_test.png)\n",
    "\n",
    "\n",
    "__Hints__: \n",
    "- Use marker `'o'` with size `300` for the centroids\n",
    "- Use the list of colours `class_colours` we provided above to distinguish the three classes. \n",
    "- We are providing you with a function called `plot_voronoi(centroids, test_set, ax)` to plot the Voronoi diagram. This functions takes three parameters:\n",
    "    - `centroids`: has to be a NumPy array of shape `(3, 2)` containing the centroids' `(x, y)` coordinates\n",
    "    - `test_set`: has to be a NumPy array of shape `(n, 2)` containing the reducted test set\n",
    "    - `ax` the matplotlib axis where to overlay the plot. If you create the figure with `fig, fig_ax = plt.subplots()` simply pass `fig_ax`. If you do not explicitily create a figure (i.e. use `plt.plot()` as opposed to `ax.plot()`), then pass `plt.gca()` to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Why are some test points incorrectly classified?\n",
    "2. How could we change our classifier so that all the test points are correctly classified?\n",
    "3. Would having all the test points correctly classified necessarily be a good thing?\n",
    "4. Our simple dataset was fully labelled and thus we could follow a supervised approach. This made our life much easier. Suppose now we did not have any class labels for the training set, and that we still wanted to use the Nearest-Centroid classifier. How could we train our classifier in such case?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers \n",
    "\n",
    "Write your answers here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
